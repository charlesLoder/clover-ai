import { Meta } from "@storybook/addon-docs/blocks";

<Meta title="Creating a provider" />

# Creating a provider

This document provides a step-by-step guide on how to pass messages from Clover AI to a custom LLM provider.

In this guide, we will:

- create a custom provider that extends the `BaseProvider` class
- create an acknowledgment screen that requires user interaction before proceeding
- send messages to a mock LLM provider and return a response

## Step 1: Create a custom provider

To create a custom provider, we need to extend the `BaseProvider` class.

This class provides the necessary methods and properties to interact with Clover AI.

```tsx
// my-custom-provider.tsx
import { BaseProvider } from "clover-ai";

export class MyCustomProvider extends BaseProvider {
  #user_accepted = false;
  constructor() {
    super();
    super.status = "initializing";
  }

  get status() {
    return this.#user_accepted ? "ready" : "initializing";
  }
}
```

By setting the `status` property to `"initializing"` in the constructor, we indicate that the provider is in the process of being set up.

We also define a getter for the `status` property that returns `"ready"` if the user has accepted the terms, or `"initializing"` otherwise.

This will allow `MyCustomProvider` to perform any setup logic like render a component when the status is `"initializing"`.

## Step 2: Create an acknowledgment screen

Next, we create an acknowledgment screen that requires user interaction before proceeding.

```tsx
// my-custom-provider.tsx
import { BaseProvider } from "clover-ai";
import { Heading, Button } from "clover-ai/components";

export class MyCustomProvider extends BaseProvider {
  #user_accepted = false;
  constructor() {
    super();
    super.status = "initializing";
  }

  get status() {
    return this.#user_accepted ? "ready" : "initializing";
  }

  // provided by BaseProvider
  SetupComponent() {
    const handleClick = () => {
      this.#user_accepted = true;

      // update the Plugin state with the modified provider
      this.update_plugin_provider();
    };

    return (
      <div>
        <Heading level={"h3"}>Welcome to My Custom Provider</Heading>
        <p>Please acknowledge that you won't use this tool for evil.</p>
        <Button onClick={handleClick} variant="primary">
          I won't
        </Button>
      </div>
    );
  }
}
```

The provider class has access to the plugin's `dispatch` method, which allows it to send messages to Clover AI.

When the user clicks the button, we set `#user_accepted` to `true` and update the plugin state with the modified provider using `this.update_plugin_provider()`.

This will trigger Clover AI to re-render the provider with the new status.

Note that we can use components from Clover AI, such as `Heading` and `Button` to maintain a consistent look and feel with the rest of the application.

## Step 3: Send messages to a mock LLM provider

Finally, we can send messages to a mock LLM provider and return a response.

```tsx
// my-custom-provider.tsx
import { BaseProvider } from "clover-ai";
import { Heading, Button } from "clover-ai/components";
import { Message } from "clover-ai/types";

export class MyCustomProvider extends BaseProvider {
  #user_accepted = false;
  constructor() {
    super();
    super.status = "initializing";
  }

  get status() {
    return this.#user_accepted ? "ready" : "initializing";
  }

  // provided by BaseProvider
  SetupComponent() {
    const handleClick = () => {
      this.#user_accepted = true;
      // update the Plugin state with the modified provider
      this.update_plugin_provider();
    };

    return (
      <div>
        <Heading level={"h3"}>Welcome to My Custom Provider</Heading>
        <p>Please acknowledge that you won't use this tool for evil.</p>
        <Button onClick={handleClick} type="button" variant="primary">
          I won't
        </Button>
      </div>
    );
  }

  async generate_response(messages: Message[], conversationHistory: Message[]): Promise<void> {
    this.set_conversation_state("assistant_responding");

    const mockWebSocket = new WebSocket("ws://mock-websocket-server");

    mockWebSocket.onopen = () => {
      mockWebSocket.send(JSON.stringify([...conversationHistory, ...messages]));
    };

    const assistantMessage: Message = {
      role: "assistant",
      content: { type: "text", content: "" },
    };

    // Add a blank message to be updated
    this.add_messages([assistantMessage]);

    mockWebSocket.onmessage = (event) => {
      const response = JSON.parse(event.data);

      if (response.text === "llm_end") {
        this.set_conversation_state("idle");
        return;
      }

      assistantMessage.content.content += response.text;
      this.update_last_message(assistantMessage);
    };
  }
}
```

In this step, we implement the `generate_response` method, which is responsible for sending messages to the mock LLM provider.

First, we set the conversation state to `"assistant_responding"` to indicate that the assistant is processing the request.

Next, we create a WebSocket connection to a mock server (you can replace this with your actual LLM provider's WebSocket URL).

When the WebSocket connection is opened, we send the conversation history and the new messages to the server.

We also create an `assistantMessage` object with an empty content field. This message will be updated as we receive responses from the mock server.

We add this message to the conversation history using `this.add_messages([assistantMessage])`.

We then listen for messages from the WebSocket server.
When a message is received, we parse the response and check if it contains the text `"llm_end"`, which indicates that the LLM has finished processing.

If it does, we set the conversation state back to `"idle"` and return.

If the response contains text, we append it to the `assistantMessage` content and update the last message in the conversation history using `this.update_last_message(assistantMessage)`.

This allows the assistant message to accumulate the response text as it comes in from the mock server.
